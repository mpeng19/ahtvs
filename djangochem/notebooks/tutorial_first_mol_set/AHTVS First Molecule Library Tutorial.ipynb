{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorials for getting started with ahtvs\n",
    "\n",
    "# First you will need to clone the repo that this notebook is in \n",
    "#(or make your own fork of it and then clone that fork)\n",
    "# If you have already done that, great job! \n",
    "\n",
    "# Now you will need to install the conda env. This depends on if you are running on MacOS or Linux \n",
    "# Also, you need to install postgress. I recommend pgadmin for creating databases\n",
    "# but this can also be done on the command line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a new set of molecules, you need to create a corresponding database file\n",
    "# These database files are located in /ahtvs/djangochem/djangochem/settings\n",
    "\n",
    "# The one we will use here is the file called \"example_postgres_db.py\"\n",
    "\n",
    "# So we will do two things\n",
    "# 1) We will create the database in pgadmin 4 (You only have to do this once, when first creating the database)\n",
    "#    a) Go to the databases tab on the left and then right click to create a database\n",
    "#    b) Name the database example_postgres_db\n",
    "#    c) For the template use template_0 (definition tab)\n",
    "#    d) Everything else can be left at its defaults\n",
    "\n",
    "# 2) Go to your terminal and make sure you are in the ahtvs environment (You have to do this everytime you want \n",
    "#    to use this database!)\n",
    "#    a) Type EXPORT_DJANGO_SETTINGS_MODULE=\"djangochem.settings.example_postgres_db\"\n",
    "#    b) Now the first time you do this, we will need to initially setup the database, the way to do this is to type\n",
    "#   (in the djangochem directory) ./manage.py migrate\n",
    "#    You should get a bunch of OK indicators\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that this is done, we can add some molecules to our database. \n",
    "# We are going to do this in a combinatorial manner, where we connect groups of fragments to centrally defined molecules\n",
    "\n",
    "# The command for this is called molgen\n",
    "\n",
    "# In the ahtvs/djangochem directory, run \n",
    "# ./manage.py molgen --h \n",
    "# To get the details on how molgen works\n",
    "\n",
    "# To make our first set of molecules, we will use the recipe file located in \n",
    "# /ahtvs/djangochem/molgen/tests/initial_test_viologen/example.json \n",
    "\n",
    "# This command is: \n",
    "\n",
    "# ./manage.py molgen example_postgres_db molgen/tests/initial_test_viologen/example.json -r noble_graft -t test_mol\n",
    "\n",
    "# This creates molecules with *tags* test_mol and grafts the cores with the fragments in a one to one manner\n",
    "# The output is: \n",
    "\n",
    "# Created 28 new molecules. Molecules are tagged with '['test_mol']'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's quickly print the smiles strings of all of the mols that we created\n",
    "\n",
    "# ./manage.py shell_plus\n",
    "\n",
    "\n",
    "# In [2]: for mol in Mol.objects.all(): \n",
    "#   ...:     print(mol.smiles)  \n",
    "#   ...:                                                                                                                                                                                                                                                                                                      \n",
    "#C[n+]1ccc(-c2cc[n+](C)cc2)cc1\n",
    "#c1ncnc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)n1\n",
    "#c1cc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)ncn1\n",
    "#c1cc(-c2cc[n+](-c3nnn[nH]3)cc2)cc[nH+]1\n",
    "#FC(F)(F)[n+]1ccc(-c2cc[nH+]cc2)cc1\n",
    "#c1cc(-[n+]2ccc(-c3cc[n+](-c4ccncc4)cc3)cc2)ccn1\n",
    "#c1c[n+](-n2cnnn2)ccc1-c1cc[n+](-n2cnnn2)cc1\n",
    "#N#C[n+]1ccc(-c2cc[n+](C#N)cc2)cc1\n",
    "#c1cnc(-[n+]2ccc(-c3cc[n+](-c4ncccn4)cc3)cc2)nc1\n",
    "#c1cc(-[n+]2ccc(-c3cc[n+](-c4ccncn4)cc3)cc2)ncn1\n",
    "#C[n+]1ccc(-c2cc[nH+]cc2)cc1\n",
    "#c1ncc(-[n+]2ccc(-c3cc[n+](-c4cncnc4)cc3)cc2)cn1\n",
    "#c1cc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)ccn1\n",
    "#c1ccc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)nc1\n",
    "#c1c[n+](-c2nnn[nH]2)ccc1-c1cc[n+](-c2nnn[nH]2)cc1\n",
    "#FC(F)(F)[n+]1ccc(-c2cc[n+](C(F)(F)F)cc2)cc1\n",
    "#CC[n+]1ccc(-c2cc[nH+]cc2)cc1\n",
    "#N#C[n+]1ccc(-c2cc[nH+]cc2)cc1\n",
    "#c1cncc(-[n+]2ccc(-c3cc[n+](-c4cccnc4)cc3)cc2)c1\n",
    "#c1ccc(-[n+]2ccc(-c3cc[n+](-c4ccccn4)cc3)cc2)nc1\n",
    "#c1ncc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)cn1\n",
    "#c1cnc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)nc1\n",
    "#c1cncc(-[n+]2ccc(-c3cc[nH+]cc3)cc2)c1\n",
    "#FC(F)(F)C[n+]1ccc(-c2cc[nH+]cc2)cc1\n",
    "#FC(F)(F)C[n+]1ccc(-c2cc[n+](CC(F)(F)F)cc2)cc1\n",
    "#c1ncnc(-[n+]2ccc(-c3cc[n+](-c4ncncn4)cc3)cc2)n1\n",
    "#CC[n+]1ccc(-c2cc[n+](CC)cc2)cc1\n",
    "#c1cc(-c2cc[n+](-n3cnnn3)cc2)cc[nH+]1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we want to generate conformers for all of these molecules \n",
    "# We first need to create conformer jobs\n",
    "\n",
    "# This is done in a three-step process in this program \n",
    "\n",
    "# 1) Step one is requesting the jobs. You can get the general form of the request jobs command with \n",
    "#    ./manage.py requestjobs --h\n",
    "\n",
    "#     Here, type \n",
    "#   ./manage.py requestjobs example_postgres_db\n",
    "\n",
    "#    First we need to load the valid job templates, or configs. You only need to do this once per project\n",
    "#   or when you create a new config file \n",
    "\n",
    "#    ./manage.py scanconfigs --update\n",
    "\n",
    "#   Now type:\n",
    "\n",
    "#   ./manage.py requestjobs example_postgres_db conformer\n",
    "#   The output is: \n",
    "\n",
    "#   Requested 28 new jobs\n",
    "\n",
    "#   The jobs are requested, but are not yet built. \n",
    "\n",
    "# 2) Step 2 is to build the jobs \n",
    "#  You need to create directory (Preferably outside of the ahtvs codebase) to store the jobs\n",
    "#  I have mine is ~/ahtvs_jobs/example_db_jobs/example_db_jobs_build/\n",
    "\n",
    "#  If you type \n",
    "#  ./manage.py buildjobs --h you will get the information on building the jobs \n",
    "\n",
    "# On my computer the command becomes: \n",
    "\n",
    "# ./manage.py buildjobs example_postgres_db /Users/danieltabor/ahtvs_jobs/example_db_jobs/example_db_jobs_build/ -c conformer\n",
    "\n",
    "#  Change the 3rd argument to match your computer \n",
    "\n",
    "# Now all of the jobs are ready to be run\n",
    "\n",
    "# Since these are conformers, we will run these locally\n",
    "\n",
    "# Let's run the first one \n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
